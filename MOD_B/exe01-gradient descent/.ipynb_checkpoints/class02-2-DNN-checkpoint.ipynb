{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "civic-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import math\n",
    "import time\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-maine",
   "metadata": {},
   "source": [
    "### Data (strings) and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monetary-hypothesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "16\n",
      "AAGGTCTGCCGGCCGA 1\n",
      "\n",
      "data: 3000\n",
      "train: 2400 \n",
      "test: 600\n"
     ]
    }
   ],
   "source": [
    "fname=\"DATA/sequences16.csv\"\n",
    "sx,sy=np.loadtxt(fname,delimiter=',', usecols=(0,1), unpack =True, dtype=str)\n",
    "N=len(sy)\n",
    "print(N)\n",
    "Ls=len(sx[0])\n",
    "print(Ls)\n",
    "print(sx[0],sy[0])\n",
    "\n",
    "\n",
    "perc_train=0.8\n",
    "N_train=int(N*perc_train)\n",
    "N_test=N-N_train\n",
    "print(f'\\ndata: {N}\\ntrain: {N_train} \\ntest: {N_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dietary-worship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'C': 1, 'G': 2, 'T': 3}\n"
     ]
    }
   ],
   "source": [
    "Q=['A','C','G','T']\n",
    "Nc=4\n",
    "onehc ={Q[i]: i for i in range(Nc)}\n",
    "print(onehc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-inflation",
   "metadata": {},
   "source": [
    "### Data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reasonable-sphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "AAGGTCTGCCGGCCGA\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y=sy.astype(int)\n",
    "\n",
    "L=Ls*Nc\n",
    "print(L)\n",
    "\n",
    "x=np.zeros((N,L))\n",
    "print(x[0])\n",
    "\n",
    "for n in range (N):\n",
    "    for i in range (Ls):\n",
    "        x[n][i*4+ onehc [sx[n][i]]]=1\n",
    "print(sx[0])\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-genealogy",
   "metadata": {},
   "source": [
    "### Split train/ test-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charming-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24333333333333335\n",
      "0.25833333333333336\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train)= (x[:N_train], y[:N_train])\n",
    "(x_test, y_test)= (x[N_train:], y[N_train:])\n",
    "\n",
    "print(y_train.sum()/N_train)\n",
    "print(y_test.sum()/N_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-riding",
   "metadata": {},
   "source": [
    "### Definition of model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moving-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,785\n",
      "Trainable params: 6,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model=Sequential()\n",
    "model.add(Dense(L,input_shape=(L,),activation=\"relu\"))\n",
    "model.add(Dense(int(L/2),activation=\"relu\"))\n",
    "model.add(Dense(int(L/4),activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extensive-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1=SGD(learning_rate=0.01,\n",
    "         momentum=0.9, #if it is =0 it's = to vanilla gd\n",
    "        nesterov=True)\n",
    "\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=opt1,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "anticipated-pavilion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0773 - accuracy: 0.9737 - val_loss: 0.7555 - val_accuracy: 0.7783\n",
      "Epoch 2/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0690 - accuracy: 0.9775 - val_loss: 0.8250 - val_accuracy: 0.7817\n",
      "Epoch 3/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0606 - accuracy: 0.9762 - val_loss: 0.9856 - val_accuracy: 0.7817\n",
      "Epoch 4/300\n",
      "2400/2400 [==============================] - 0s 38us/step - loss: 0.0555 - accuracy: 0.9837 - val_loss: 0.8549 - val_accuracy: 0.7683\n",
      "Epoch 5/300\n",
      "2400/2400 [==============================] - 0s 38us/step - loss: 0.0473 - accuracy: 0.9875 - val_loss: 0.8399 - val_accuracy: 0.7933\n",
      "Epoch 6/300\n",
      "2400/2400 [==============================] - 0s 42us/step - loss: 0.0394 - accuracy: 0.9917 - val_loss: 0.8971 - val_accuracy: 0.7767\n",
      "Epoch 7/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0268 - accuracy: 0.9958 - val_loss: 0.9303 - val_accuracy: 0.7833\n",
      "Epoch 8/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0194 - accuracy: 0.9987 - val_loss: 1.0037 - val_accuracy: 0.7883\n",
      "Epoch 9/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.9794 - val_accuracy: 0.7783\n",
      "Epoch 10/300\n",
      "2400/2400 [==============================] - 0s 38us/step - loss: 0.0218 - accuracy: 0.9958 - val_loss: 1.0571 - val_accuracy: 0.7917\n",
      "Epoch 11/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 1.0769 - val_accuracy: 0.7983\n",
      "Epoch 12/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 1.0808 - val_accuracy: 0.7717\n",
      "Epoch 13/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 1.0910 - val_accuracy: 0.7800\n",
      "Epoch 14/300\n",
      "2400/2400 [==============================] - 0s 36us/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 1.1796 - val_accuracy: 0.7933\n",
      "Epoch 15/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0131 - accuracy: 0.9987 - val_loss: 1.1217 - val_accuracy: 0.7767\n",
      "Epoch 16/300\n",
      "2400/2400 [==============================] - 0s 36us/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 1.1600 - val_accuracy: 0.7900\n",
      "Epoch 17/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 1.1123 - val_accuracy: 0.7867\n",
      "Epoch 18/300\n",
      "2400/2400 [==============================] - 0s 36us/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 1.1655 - val_accuracy: 0.7817\n",
      "Epoch 19/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 1.1204 - val_accuracy: 0.7733\n",
      "Epoch 20/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 1.2751 - val_accuracy: 0.7783\n",
      "Epoch 21/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 0.0173 - accuracy: 0.9962 - val_loss: 1.2891 - val_accuracy: 0.7983\n",
      "Epoch 22/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 1.1694 - val_accuracy: 0.7733\n",
      "Epoch 23/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 1.2644 - val_accuracy: 0.7750\n",
      "Epoch 24/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 1.2262 - val_accuracy: 0.7867\n",
      "Epoch 25/300\n",
      "2400/2400 [==============================] - 0s 39us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1918 - val_accuracy: 0.7933\n",
      "Epoch 26/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2831 - val_accuracy: 0.7983\n",
      "Epoch 27/300\n",
      "2400/2400 [==============================] - 0s 26us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2616 - val_accuracy: 0.7917\n",
      "Epoch 28/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.2953 - val_accuracy: 0.7917\n",
      "Epoch 29/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.3147 - val_accuracy: 0.7867\n",
      "Epoch 30/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 1.3164 - val_accuracy: 0.7917\n",
      "Epoch 31/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3509 - val_accuracy: 0.7950\n",
      "Epoch 32/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3398 - val_accuracy: 0.7917\n",
      "Epoch 33/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 1.3670 - val_accuracy: 0.7950\n",
      "Epoch 34/300\n",
      "2400/2400 [==============================] - 0s 24us/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.3970 - val_accuracy: 0.7867\n",
      "Epoch 35/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 1.5187 - val_accuracy: 0.7817\n",
      "Epoch 36/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 0.0242 - accuracy: 0.9904 - val_loss: 1.2580 - val_accuracy: 0.7783\n",
      "Epoch 37/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 1.3239 - val_accuracy: 0.7700\n",
      "Epoch 38/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0296 - accuracy: 0.9883 - val_loss: 1.3002 - val_accuracy: 0.7850\n",
      "Epoch 39/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0539 - accuracy: 0.9796 - val_loss: 1.2689 - val_accuracy: 0.7617\n",
      "Epoch 40/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 0.0576 - accuracy: 0.9821 - val_loss: 1.2932 - val_accuracy: 0.7900\n",
      "Epoch 41/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0375 - accuracy: 0.9867 - val_loss: 1.2107 - val_accuracy: 0.7617\n",
      "Epoch 42/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 1.2896 - val_accuracy: 0.7700\n",
      "Epoch 43/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 1.3024 - val_accuracy: 0.7700\n",
      "Epoch 44/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 1.3002 - val_accuracy: 0.7967\n",
      "Epoch 45/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 1.4049 - val_accuracy: 0.7833\n",
      "Epoch 46/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.4062 - val_accuracy: 0.7883\n",
      "Epoch 47/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4601 - val_accuracy: 0.7833\n",
      "Epoch 48/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.4244 - val_accuracy: 0.7817\n",
      "Epoch 49/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.5107 - val_accuracy: 0.7867\n",
      "Epoch 50/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 1.4751 - val_accuracy: 0.7817\n",
      "Epoch 51/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5077 - val_accuracy: 0.7833\n",
      "Epoch 52/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.4865 - val_accuracy: 0.7850\n",
      "Epoch 53/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5365 - val_accuracy: 0.7867\n",
      "Epoch 54/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5497 - val_accuracy: 0.7850\n",
      "Epoch 55/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.7867\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6053 - val_accuracy: 0.7833\n",
      "Epoch 57/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5604 - val_accuracy: 0.7883\n",
      "Epoch 58/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5722 - val_accuracy: 0.7900\n",
      "Epoch 59/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5954 - val_accuracy: 0.7867\n",
      "Epoch 60/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5850 - val_accuracy: 0.7850\n",
      "Epoch 61/300\n",
      "2400/2400 [==============================] - 0s 40us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.7817\n",
      "Epoch 62/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.7833\n",
      "Epoch 63/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6476 - val_accuracy: 0.7867\n",
      "Epoch 64/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7043 - val_accuracy: 0.7917\n",
      "Epoch 65/300\n",
      "2400/2400 [==============================] - 0s 39us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6710 - val_accuracy: 0.7883\n",
      "Epoch 66/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.7031 - val_accuracy: 0.7933\n",
      "Epoch 67/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 9.1483e-04 - accuracy: 1.0000 - val_loss: 1.6671 - val_accuracy: 0.7867\n",
      "Epoch 68/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6780 - val_accuracy: 0.7883\n",
      "Epoch 69/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6863 - val_accuracy: 0.7917\n",
      "Epoch 70/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7003 - val_accuracy: 0.7883\n",
      "Epoch 71/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 7.7137e-04 - accuracy: 1.0000 - val_loss: 1.6867 - val_accuracy: 0.7883\n",
      "Epoch 72/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 8.6743e-04 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.7867\n",
      "Epoch 73/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.7576 - val_accuracy: 0.7900\n",
      "Epoch 74/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 8.8021e-04 - accuracy: 1.0000 - val_loss: 1.7059 - val_accuracy: 0.7917\n",
      "Epoch 75/300\n",
      "2400/2400 [==============================] - 0s 26us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7124 - val_accuracy: 0.7900\n",
      "Epoch 76/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.7372 - val_accuracy: 0.7933\n",
      "Epoch 77/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7426 - val_accuracy: 0.7933\n",
      "Epoch 78/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 8.8730e-04 - accuracy: 1.0000 - val_loss: 1.7179 - val_accuracy: 0.7867\n",
      "Epoch 79/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.7239 - val_accuracy: 0.7867\n",
      "Epoch 80/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 8.0576e-04 - accuracy: 1.0000 - val_loss: 1.7082 - val_accuracy: 0.7883\n",
      "Epoch 81/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 7.8984e-04 - accuracy: 1.0000 - val_loss: 1.7482 - val_accuracy: 0.7950\n",
      "Epoch 82/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.7163 - val_accuracy: 0.7850\n",
      "Epoch 83/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7755 - val_accuracy: 0.7917\n",
      "Epoch 84/300\n",
      "2400/2400 [==============================] - 0s 25us/step - loss: 6.1222e-04 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.7867\n",
      "Epoch 85/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 7.1278e-04 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.7917\n",
      "Epoch 86/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 4.5017e-04 - accuracy: 1.0000 - val_loss: 1.7463 - val_accuracy: 0.7933\n",
      "Epoch 87/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 6.7158e-04 - accuracy: 1.0000 - val_loss: 1.7485 - val_accuracy: 0.7950\n",
      "Epoch 88/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 7.7387e-04 - accuracy: 1.0000 - val_loss: 1.7705 - val_accuracy: 0.7917\n",
      "Epoch 89/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 4.9816e-04 - accuracy: 1.0000 - val_loss: 1.7638 - val_accuracy: 0.7917\n",
      "Epoch 90/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 8.3143e-04 - accuracy: 1.0000 - val_loss: 1.7895 - val_accuracy: 0.7917\n",
      "Epoch 91/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8083 - val_accuracy: 0.7883\n",
      "Epoch 92/300\n",
      "2400/2400 [==============================] - 0s 42us/step - loss: 7.0981e-04 - accuracy: 1.0000 - val_loss: 1.7696 - val_accuracy: 0.7900\n",
      "Epoch 93/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 5.4976e-04 - accuracy: 1.0000 - val_loss: 1.7818 - val_accuracy: 0.7967\n",
      "Epoch 94/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 7.2420e-04 - accuracy: 1.0000 - val_loss: 1.7826 - val_accuracy: 0.7933\n",
      "Epoch 95/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 5.0199e-04 - accuracy: 1.0000 - val_loss: 1.7706 - val_accuracy: 0.7883\n",
      "Epoch 96/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 7.2946e-04 - accuracy: 1.0000 - val_loss: 1.7937 - val_accuracy: 0.7950\n",
      "Epoch 97/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 8.1571e-04 - accuracy: 1.0000 - val_loss: 1.7663 - val_accuracy: 0.7983\n",
      "Epoch 98/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 8.0384e-04 - accuracy: 1.0000 - val_loss: 1.7706 - val_accuracy: 0.7983\n",
      "Epoch 99/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 6.4999e-04 - accuracy: 1.0000 - val_loss: 1.8910 - val_accuracy: 0.7917\n",
      "Epoch 100/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8371 - val_accuracy: 0.7900\n",
      "Epoch 101/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 9.5604e-04 - accuracy: 1.0000 - val_loss: 1.8028 - val_accuracy: 0.7900\n",
      "Epoch 102/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 4.7437e-04 - accuracy: 1.0000 - val_loss: 1.8179 - val_accuracy: 0.7900\n",
      "Epoch 103/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 4.8324e-04 - accuracy: 1.0000 - val_loss: 1.8107 - val_accuracy: 0.7950\n",
      "Epoch 104/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.8549 - val_accuracy: 0.7917\n",
      "Epoch 105/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.8763 - val_accuracy: 0.7850\n",
      "Epoch 106/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 4.7729e-04 - accuracy: 1.0000 - val_loss: 1.8330 - val_accuracy: 0.7900\n",
      "Epoch 107/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.7011e-04 - accuracy: 1.0000 - val_loss: 1.8488 - val_accuracy: 0.7917\n",
      "Epoch 108/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 6.1021e-04 - accuracy: 1.0000 - val_loss: 1.8336 - val_accuracy: 0.7900\n",
      "Epoch 109/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.2040e-04 - accuracy: 1.0000 - val_loss: 1.8656 - val_accuracy: 0.7900\n",
      "Epoch 110/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 4.1741e-04 - accuracy: 1.0000 - val_loss: 1.8472 - val_accuracy: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.9447 - val_accuracy: 0.7933\n",
      "Epoch 112/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 6.0727e-04 - accuracy: 1.0000 - val_loss: 1.8771 - val_accuracy: 0.7933\n",
      "Epoch 113/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 7.2184e-04 - accuracy: 1.0000 - val_loss: 1.8545 - val_accuracy: 0.7933\n",
      "Epoch 114/300\n",
      "2400/2400 [==============================] - 0s 26us/step - loss: 4.1172e-04 - accuracy: 1.0000 - val_loss: 1.8671 - val_accuracy: 0.7933\n",
      "Epoch 115/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.2432e-04 - accuracy: 1.0000 - val_loss: 1.8737 - val_accuracy: 0.7933\n",
      "Epoch 116/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 6.5520e-04 - accuracy: 1.0000 - val_loss: 1.8693 - val_accuracy: 0.7950\n",
      "Epoch 117/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 1.9656 - val_accuracy: 0.7933\n",
      "Epoch 118/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 7.8132e-04 - accuracy: 1.0000 - val_loss: 1.8563 - val_accuracy: 0.7883\n",
      "Epoch 119/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 6.0097e-04 - accuracy: 1.0000 - val_loss: 1.8932 - val_accuracy: 0.7883\n",
      "Epoch 120/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 1.8905 - val_accuracy: 0.7950\n",
      "Epoch 121/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 3.7535e-04 - accuracy: 1.0000 - val_loss: 1.8899 - val_accuracy: 0.7917\n",
      "Epoch 122/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 9.9733e-04 - accuracy: 0.9996 - val_loss: 1.9250 - val_accuracy: 0.7883\n",
      "Epoch 123/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 3.0791e-04 - accuracy: 1.0000 - val_loss: 1.9307 - val_accuracy: 0.7917\n",
      "Epoch 124/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 5.2933e-04 - accuracy: 1.0000 - val_loss: 1.9494 - val_accuracy: 0.7867\n",
      "Epoch 125/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 3.3531e-04 - accuracy: 1.0000 - val_loss: 1.9579 - val_accuracy: 0.7850\n",
      "Epoch 126/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 3.7786e-04 - accuracy: 1.0000 - val_loss: 1.9130 - val_accuracy: 0.7917\n",
      "Epoch 127/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 5.3035e-04 - accuracy: 1.0000 - val_loss: 1.9172 - val_accuracy: 0.7900\n",
      "Epoch 128/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 4.5801e-04 - accuracy: 1.0000 - val_loss: 1.9385 - val_accuracy: 0.7900\n",
      "Epoch 129/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 4.2692e-04 - accuracy: 1.0000 - val_loss: 1.9476 - val_accuracy: 0.7850\n",
      "Epoch 130/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 1.9753e-04 - accuracy: 1.0000 - val_loss: 1.9273 - val_accuracy: 0.7883\n",
      "Epoch 131/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 4.1649e-04 - accuracy: 1.0000 - val_loss: 1.9418 - val_accuracy: 0.7883\n",
      "Epoch 132/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 5.7563e-04 - accuracy: 1.0000 - val_loss: 1.9099 - val_accuracy: 0.7883\n",
      "Epoch 133/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 3.4994e-04 - accuracy: 1.0000 - val_loss: 1.8980 - val_accuracy: 0.7917\n",
      "Epoch 134/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 2.1203e-04 - accuracy: 1.0000 - val_loss: 1.9068 - val_accuracy: 0.7900\n",
      "Epoch 135/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 6.0449e-04 - accuracy: 1.0000 - val_loss: 1.9673 - val_accuracy: 0.7917\n",
      "Epoch 136/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 4.7941e-04 - accuracy: 1.0000 - val_loss: 1.9341 - val_accuracy: 0.7933\n",
      "Epoch 137/300\n",
      "2400/2400 [==============================] - 0s 43us/step - loss: 4.7899e-04 - accuracy: 1.0000 - val_loss: 1.9197 - val_accuracy: 0.7950\n",
      "Epoch 138/300\n",
      "2400/2400 [==============================] - 0s 40us/step - loss: 8.1747e-04 - accuracy: 1.0000 - val_loss: 1.9770 - val_accuracy: 0.7933\n",
      "Epoch 139/300\n",
      "2400/2400 [==============================] - 0s 38us/step - loss: 6.9600e-04 - accuracy: 1.0000 - val_loss: 2.0040 - val_accuracy: 0.7900\n",
      "Epoch 140/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 2.8667e-04 - accuracy: 1.0000 - val_loss: 1.9474 - val_accuracy: 0.7950\n",
      "Epoch 141/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 3.5666e-04 - accuracy: 1.0000 - val_loss: 1.9477 - val_accuracy: 0.7933\n",
      "Epoch 142/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.3162e-04 - accuracy: 1.0000 - val_loss: 1.9340 - val_accuracy: 0.7950\n",
      "Epoch 143/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 3.9636e-04 - accuracy: 1.0000 - val_loss: 1.9815 - val_accuracy: 0.7917\n",
      "Epoch 144/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 4.7192e-04 - accuracy: 1.0000 - val_loss: 1.9682 - val_accuracy: 0.7900\n",
      "Epoch 145/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 3.8497e-04 - accuracy: 1.0000 - val_loss: 1.9450 - val_accuracy: 0.7933\n",
      "Epoch 146/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 5.7495e-04 - accuracy: 1.0000 - val_loss: 1.9239 - val_accuracy: 0.7817\n",
      "Epoch 147/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 3.9130e-04 - accuracy: 1.0000 - val_loss: 1.9174 - val_accuracy: 0.7833\n",
      "Epoch 148/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 7.4402e-04 - accuracy: 1.0000 - val_loss: 1.9539 - val_accuracy: 0.7883\n",
      "Epoch 149/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.0696e-04 - accuracy: 1.0000 - val_loss: 1.9547 - val_accuracy: 0.7833\n",
      "Epoch 150/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 2.5213e-04 - accuracy: 1.0000 - val_loss: 1.9284 - val_accuracy: 0.7867\n",
      "Epoch 151/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 8.8460e-04 - accuracy: 0.9996 - val_loss: 1.9888 - val_accuracy: 0.7933\n",
      "Epoch 152/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.9023e-04 - accuracy: 1.0000 - val_loss: 2.0085 - val_accuracy: 0.7967\n",
      "Epoch 153/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 4.6533e-04 - accuracy: 1.0000 - val_loss: 2.0001 - val_accuracy: 0.7883\n",
      "Epoch 154/300\n",
      "2400/2400 [==============================] - 0s 25us/step - loss: 3.5270e-04 - accuracy: 1.0000 - val_loss: 1.9717 - val_accuracy: 0.7850\n",
      "Epoch 155/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 7.2213e-04 - accuracy: 1.0000 - val_loss: 1.9888 - val_accuracy: 0.7867\n",
      "Epoch 156/300\n",
      "2400/2400 [==============================] - 0s 40us/step - loss: 6.8387e-04 - accuracy: 1.0000 - val_loss: 1.9886 - val_accuracy: 0.7850\n",
      "Epoch 157/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 4.4123e-04 - accuracy: 1.0000 - val_loss: 2.0336 - val_accuracy: 0.7883\n",
      "Epoch 158/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 5.3242e-04 - accuracy: 1.0000 - val_loss: 1.9932 - val_accuracy: 0.7867\n",
      "Epoch 159/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 4.3936e-04 - accuracy: 1.0000 - val_loss: 1.9653 - val_accuracy: 0.7950\n",
      "Epoch 160/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 4.4374e-04 - accuracy: 1.0000 - val_loss: 1.9699 - val_accuracy: 0.7950\n",
      "Epoch 161/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.6053e-04 - accuracy: 1.0000 - val_loss: 1.9546 - val_accuracy: 0.7933\n",
      "Epoch 162/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 6.0599e-04 - accuracy: 0.9996 - val_loss: 1.9821 - val_accuracy: 0.7917\n",
      "Epoch 163/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 2.9940e-04 - accuracy: 1.0000 - val_loss: 1.9682 - val_accuracy: 0.7933\n",
      "Epoch 164/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 2.3441e-04 - accuracy: 1.0000 - val_loss: 1.9835 - val_accuracy: 0.7883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 2.0655 - val_accuracy: 0.7833\n",
      "Epoch 166/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 7.8865e-04 - accuracy: 1.0000 - val_loss: 2.0594 - val_accuracy: 0.7850\n",
      "Epoch 167/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.9267e-04 - accuracy: 1.0000 - val_loss: 2.0694 - val_accuracy: 0.7800\n",
      "Epoch 168/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 4.8748e-04 - accuracy: 1.0000 - val_loss: 2.0758 - val_accuracy: 0.7800\n",
      "Epoch 169/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 4.6357e-04 - accuracy: 1.0000 - val_loss: 2.0555 - val_accuracy: 0.7867\n",
      "Epoch 170/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 6.2671e-04 - accuracy: 1.0000 - val_loss: 2.0651 - val_accuracy: 0.7833\n",
      "Epoch 171/300\n",
      "2400/2400 [==============================] - ETA: 0s - loss: 6.7504e-04 - accuracy: 1.00 - 0s 33us/step - loss: 5.7562e-04 - accuracy: 1.0000 - val_loss: 2.0581 - val_accuracy: 0.7867\n",
      "Epoch 172/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 7.8002e-04 - accuracy: 0.9996 - val_loss: 2.0548 - val_accuracy: 0.7883\n",
      "Epoch 173/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.9129e-04 - accuracy: 1.0000 - val_loss: 2.0052 - val_accuracy: 0.7883\n",
      "Epoch 174/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 5.2339e-04 - accuracy: 1.0000 - val_loss: 2.0574 - val_accuracy: 0.7950\n",
      "Epoch 175/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 2.1389e-04 - accuracy: 1.0000 - val_loss: 2.0308 - val_accuracy: 0.7950\n",
      "Epoch 176/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.0057e-04 - accuracy: 1.0000 - val_loss: 2.0246 - val_accuracy: 0.7933\n",
      "Epoch 177/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 4.3348e-04 - accuracy: 1.0000 - val_loss: 2.0680 - val_accuracy: 0.7950\n",
      "Epoch 178/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.9547e-04 - accuracy: 1.0000 - val_loss: 2.0325 - val_accuracy: 0.7950\n",
      "Epoch 179/300\n",
      "2400/2400 [==============================] - 0s 28us/step - loss: 3.1320e-04 - accuracy: 1.0000 - val_loss: 2.0127 - val_accuracy: 0.7967\n",
      "Epoch 180/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 2.4472e-04 - accuracy: 1.0000 - val_loss: 2.0339 - val_accuracy: 0.7950\n",
      "Epoch 181/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 6.1328e-04 - accuracy: 1.0000 - val_loss: 1.9849 - val_accuracy: 0.7917\n",
      "Epoch 182/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.5192e-04 - accuracy: 1.0000 - val_loss: 2.0304 - val_accuracy: 0.7967\n",
      "Epoch 183/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 2.5849e-04 - accuracy: 1.0000 - val_loss: 2.0120 - val_accuracy: 0.7967\n",
      "Epoch 184/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 3.6666e-04 - accuracy: 1.0000 - val_loss: 2.0044 - val_accuracy: 0.7983\n",
      "Epoch 185/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 1.9590e-04 - accuracy: 1.0000 - val_loss: 2.0142 - val_accuracy: 0.7983\n",
      "Epoch 186/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 3.6695e-04 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.8017\n",
      "Epoch 187/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.4922e-04 - accuracy: 1.0000 - val_loss: 1.9968 - val_accuracy: 0.8000\n",
      "Epoch 188/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.5041e-04 - accuracy: 1.0000 - val_loss: 2.0056 - val_accuracy: 0.7983\n",
      "Epoch 189/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.8154e-04 - accuracy: 1.0000 - val_loss: 2.0255 - val_accuracy: 0.7967\n",
      "Epoch 190/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.9037e-04 - accuracy: 1.0000 - val_loss: 1.9903 - val_accuracy: 0.8017\n",
      "Epoch 191/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 5.8939e-04 - accuracy: 1.0000 - val_loss: 1.9998 - val_accuracy: 0.7933\n",
      "Epoch 192/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 8.7312e-04 - accuracy: 1.0000 - val_loss: 2.1640 - val_accuracy: 0.7900\n",
      "Epoch 193/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 6.9786e-04 - accuracy: 1.0000 - val_loss: 2.0350 - val_accuracy: 0.7900\n",
      "Epoch 194/300\n",
      "2400/2400 [==============================] - 0s 44us/step - loss: 5.0995e-04 - accuracy: 1.0000 - val_loss: 2.0266 - val_accuracy: 0.7933\n",
      "Epoch 195/300\n",
      "2400/2400 [==============================] - 0s 39us/step - loss: 2.4034e-04 - accuracy: 1.0000 - val_loss: 2.0333 - val_accuracy: 0.7950\n",
      "Epoch 196/300\n",
      "2400/2400 [==============================] - 0s 36us/step - loss: 2.9434e-04 - accuracy: 1.0000 - val_loss: 2.0357 - val_accuracy: 0.7917\n",
      "Epoch 197/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 4.5036e-04 - accuracy: 1.0000 - val_loss: 1.9938 - val_accuracy: 0.7850\n",
      "Epoch 198/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 9.5438e-04 - accuracy: 0.9996 - val_loss: 2.0098 - val_accuracy: 0.7900\n",
      "Epoch 199/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 1.7724e-04 - accuracy: 1.0000 - val_loss: 2.0216 - val_accuracy: 0.7917\n",
      "Epoch 200/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 6.1037e-04 - accuracy: 1.0000 - val_loss: 2.0280 - val_accuracy: 0.7900\n",
      "Epoch 201/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 2.2526e-04 - accuracy: 1.0000 - val_loss: 2.0708 - val_accuracy: 0.7950\n",
      "Epoch 202/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 2.2874e-04 - accuracy: 1.0000 - val_loss: 2.0569 - val_accuracy: 0.7933\n",
      "Epoch 203/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 3.2435e-04 - accuracy: 1.0000 - val_loss: 2.0738 - val_accuracy: 0.7967\n",
      "Epoch 204/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 3.7404e-04 - accuracy: 1.0000 - val_loss: 2.0540 - val_accuracy: 0.7917\n",
      "Epoch 205/300\n",
      "2400/2400 [==============================] - 0s 27us/step - loss: 3.8385e-04 - accuracy: 1.0000 - val_loss: 2.0534 - val_accuracy: 0.7933\n",
      "Epoch 206/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.3979e-04 - accuracy: 1.0000 - val_loss: 2.0537 - val_accuracy: 0.7933\n",
      "Epoch 207/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.6506e-04 - accuracy: 1.0000 - val_loss: 2.0497 - val_accuracy: 0.7900\n",
      "Epoch 208/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 5.8973e-04 - accuracy: 0.9996 - val_loss: 2.0565 - val_accuracy: 0.7933\n",
      "Epoch 209/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 4.1967e-04 - accuracy: 1.0000 - val_loss: 2.0302 - val_accuracy: 0.7900\n",
      "Epoch 210/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 3.3177e-04 - accuracy: 1.0000 - val_loss: 2.0596 - val_accuracy: 0.7933\n",
      "Epoch 211/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 1.7302e-04 - accuracy: 1.0000 - val_loss: 2.0540 - val_accuracy: 0.7933\n",
      "Epoch 212/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.1229e-04 - accuracy: 1.0000 - val_loss: 2.0722 - val_accuracy: 0.7950\n",
      "Epoch 213/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.8093e-04 - accuracy: 1.0000 - val_loss: 2.0567 - val_accuracy: 0.7983\n",
      "Epoch 214/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 1.6129e-04 - accuracy: 1.0000 - val_loss: 2.0630 - val_accuracy: 0.7967\n",
      "Epoch 215/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 6.5084e-04 - accuracy: 1.0000 - val_loss: 2.1339 - val_accuracy: 0.7983\n",
      "Epoch 216/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 3.4163e-04 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.8000\n",
      "Epoch 217/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 2.1756e-04 - accuracy: 1.0000 - val_loss: 2.0509 - val_accuracy: 0.7967\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 29us/step - loss: 6.2815e-04 - accuracy: 1.0000 - val_loss: 2.0614 - val_accuracy: 0.7950\n",
      "Epoch 219/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.6444e-04 - accuracy: 1.0000 - val_loss: 2.0736 - val_accuracy: 0.7983\n",
      "Epoch 220/300\n",
      "2400/2400 [==============================] - 0s 40us/step - loss: 3.8588e-04 - accuracy: 1.0000 - val_loss: 2.0724 - val_accuracy: 0.7950\n",
      "Epoch 221/300\n",
      "2400/2400 [==============================] - 0s 39us/step - loss: 2.8283e-04 - accuracy: 1.0000 - val_loss: 2.0584 - val_accuracy: 0.7983\n",
      "Epoch 222/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 3.8764e-04 - accuracy: 1.0000 - val_loss: 2.1032 - val_accuracy: 0.8000\n",
      "Epoch 223/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 4.5695e-04 - accuracy: 0.9996 - val_loss: 2.0817 - val_accuracy: 0.7900\n",
      "Epoch 224/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 1.9244e-04 - accuracy: 1.0000 - val_loss: 2.0842 - val_accuracy: 0.7900\n",
      "Epoch 225/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.4529e-04 - accuracy: 1.0000 - val_loss: 2.1107 - val_accuracy: 0.7950\n",
      "Epoch 226/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 1.4387e-04 - accuracy: 1.0000 - val_loss: 2.1033 - val_accuracy: 0.7933\n",
      "Epoch 227/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 3.0811e-04 - accuracy: 1.0000 - val_loss: 2.1061 - val_accuracy: 0.7917\n",
      "Epoch 228/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 8.3704e-04 - accuracy: 1.0000 - val_loss: 2.1304 - val_accuracy: 0.7933\n",
      "Epoch 229/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 7.1353e-04 - accuracy: 1.0000 - val_loss: 2.0886 - val_accuracy: 0.7950\n",
      "Epoch 230/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 2.4893e-04 - accuracy: 1.0000 - val_loss: 2.0911 - val_accuracy: 0.7933\n",
      "Epoch 231/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 2.9613e-04 - accuracy: 1.0000 - val_loss: 2.1021 - val_accuracy: 0.7917\n",
      "Epoch 232/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 4.4371e-04 - accuracy: 1.0000 - val_loss: 2.1266 - val_accuracy: 0.7983\n",
      "Epoch 233/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 7.4554e-04 - accuracy: 0.9996 - val_loss: 2.1279 - val_accuracy: 0.7983\n",
      "Epoch 234/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 2.2049e-04 - accuracy: 1.0000 - val_loss: 2.1177 - val_accuracy: 0.7900\n",
      "Epoch 235/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 2.6228e-04 - accuracy: 1.0000 - val_loss: 2.1033 - val_accuracy: 0.7883\n",
      "Epoch 236/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 1.9124e-04 - accuracy: 1.0000 - val_loss: 2.1097 - val_accuracy: 0.7917\n",
      "Epoch 237/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 2.8869e-04 - accuracy: 1.0000 - val_loss: 2.1058 - val_accuracy: 0.7933\n",
      "Epoch 238/300\n",
      "2400/2400 [==============================] - 0s 36us/step - loss: 2.7799e-04 - accuracy: 1.0000 - val_loss: 2.1364 - val_accuracy: 0.7933\n",
      "Epoch 239/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 2.9131e-04 - accuracy: 1.0000 - val_loss: 2.0871 - val_accuracy: 0.7917\n",
      "Epoch 240/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 2.4420e-04 - accuracy: 1.0000 - val_loss: 2.1136 - val_accuracy: 0.7900\n",
      "Epoch 241/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 1.8273e-04 - accuracy: 1.0000 - val_loss: 2.1048 - val_accuracy: 0.7933\n",
      "Epoch 242/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 1.7258e-04 - accuracy: 1.0000 - val_loss: 2.1144 - val_accuracy: 0.7933\n",
      "Epoch 243/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 2.3405e-04 - accuracy: 1.0000 - val_loss: 2.1087 - val_accuracy: 0.7967\n",
      "Epoch 244/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 2.2871 - val_accuracy: 0.7817\n",
      "Epoch 245/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0710 - accuracy: 0.9771 - val_loss: 1.8037 - val_accuracy: 0.7750\n",
      "Epoch 246/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.1794 - accuracy: 0.9479 - val_loss: 1.3395 - val_accuracy: 0.7533\n",
      "Epoch 247/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 0.0543 - accuracy: 0.9812 - val_loss: 1.3486 - val_accuracy: 0.7650\n",
      "Epoch 248/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 1.3646 - val_accuracy: 0.7800\n",
      "Epoch 249/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 1.3312 - val_accuracy: 0.7783\n",
      "Epoch 250/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0216 - accuracy: 0.9917 - val_loss: 1.3855 - val_accuracy: 0.7767\n",
      "Epoch 251/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 1.4411 - val_accuracy: 0.7683\n",
      "Epoch 252/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 1.4736 - val_accuracy: 0.7783\n",
      "Epoch 253/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 1.5503 - val_accuracy: 0.7767\n",
      "Epoch 254/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5059 - val_accuracy: 0.7800\n",
      "Epoch 255/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.7800\n",
      "Epoch 256/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.5503 - val_accuracy: 0.7800\n",
      "Epoch 257/300\n",
      "2400/2400 [==============================] - 0s 37us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5775 - val_accuracy: 0.7783\n",
      "Epoch 258/300\n",
      "2400/2400 [==============================] - 0s 36us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.5813 - val_accuracy: 0.7783\n",
      "Epoch 259/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6024 - val_accuracy: 0.7800\n",
      "Epoch 260/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 9.0077e-04 - accuracy: 1.0000 - val_loss: 1.6231 - val_accuracy: 0.7800\n",
      "Epoch 261/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 7.2397e-04 - accuracy: 1.0000 - val_loss: 1.6266 - val_accuracy: 0.7850\n",
      "Epoch 262/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6588 - val_accuracy: 0.7833\n",
      "Epoch 263/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 9.1307e-04 - accuracy: 1.0000 - val_loss: 1.6618 - val_accuracy: 0.7867\n",
      "Epoch 264/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 5.3163e-04 - accuracy: 1.0000 - val_loss: 1.6728 - val_accuracy: 0.7850\n",
      "Epoch 265/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 8.9063e-04 - accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.7850\n",
      "Epoch 266/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7127 - val_accuracy: 0.7833\n",
      "Epoch 267/300\n",
      "2400/2400 [==============================] - ETA: 0s - loss: 5.8945e-04 - accuracy: 1.00 - 0s 33us/step - loss: 9.9680e-04 - accuracy: 0.9996 - val_loss: 1.7282 - val_accuracy: 0.7850\n",
      "Epoch 268/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 5.8490e-04 - accuracy: 1.0000 - val_loss: 1.7259 - val_accuracy: 0.7817\n",
      "Epoch 269/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 8.3371e-04 - accuracy: 1.0000 - val_loss: 1.7289 - val_accuracy: 0.7800\n",
      "Epoch 270/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 6.7870e-04 - accuracy: 1.0000 - val_loss: 1.7378 - val_accuracy: 0.7750\n",
      "Epoch 271/300\n",
      "2400/2400 [==============================] - 0s 35us/step - loss: 5.7231e-04 - accuracy: 1.0000 - val_loss: 1.7477 - val_accuracy: 0.7817\n",
      "Epoch 272/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 33us/step - loss: 6.5199e-04 - accuracy: 1.0000 - val_loss: 1.7762 - val_accuracy: 0.7800\n",
      "Epoch 273/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 4.4557e-04 - accuracy: 1.0000 - val_loss: 1.7751 - val_accuracy: 0.7817\n",
      "Epoch 274/300\n",
      "2400/2400 [==============================] - ETA: 0s - loss: 5.2262e-04 - accuracy: 1.00 - 0s 32us/step - loss: 5.0426e-04 - accuracy: 1.0000 - val_loss: 1.7807 - val_accuracy: 0.7833\n",
      "Epoch 275/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 6.1925e-04 - accuracy: 1.0000 - val_loss: 1.7971 - val_accuracy: 0.7833\n",
      "Epoch 276/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 5.0297e-04 - accuracy: 1.0000 - val_loss: 1.7931 - val_accuracy: 0.7833\n",
      "Epoch 277/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.3480e-04 - accuracy: 1.0000 - val_loss: 1.8018 - val_accuracy: 0.7817\n",
      "Epoch 278/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 5.5750e-04 - accuracy: 1.0000 - val_loss: 1.8061 - val_accuracy: 0.7817\n",
      "Epoch 279/300\n",
      "2400/2400 [==============================] - 0s 34us/step - loss: 6.0495e-04 - accuracy: 1.0000 - val_loss: 1.8265 - val_accuracy: 0.7817\n",
      "Epoch 280/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 8.2765e-04 - accuracy: 1.0000 - val_loss: 1.8298 - val_accuracy: 0.7800\n",
      "Epoch 281/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.7615e-04 - accuracy: 1.0000 - val_loss: 1.8375 - val_accuracy: 0.7800\n",
      "Epoch 282/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 8.9096e-04 - accuracy: 1.0000 - val_loss: 1.8607 - val_accuracy: 0.7783\n",
      "Epoch 283/300\n",
      "2400/2400 [==============================] - 0s 33us/step - loss: 4.3975e-04 - accuracy: 1.0000 - val_loss: 1.8536 - val_accuracy: 0.7800\n",
      "Epoch 284/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.1039e-04 - accuracy: 1.0000 - val_loss: 1.8624 - val_accuracy: 0.7817\n",
      "Epoch 285/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.0035e-04 - accuracy: 1.0000 - val_loss: 1.8565 - val_accuracy: 0.7850\n",
      "Epoch 286/300\n",
      "2400/2400 [==============================] - 0s 29us/step - loss: 4.6589e-04 - accuracy: 1.0000 - val_loss: 1.8812 - val_accuracy: 0.7783\n",
      "Epoch 287/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.9592e-04 - accuracy: 1.0000 - val_loss: 1.9268 - val_accuracy: 0.7800\n",
      "Epoch 288/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 8.7780e-04 - accuracy: 1.0000 - val_loss: 1.8858 - val_accuracy: 0.7783\n",
      "Epoch 289/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 5.2277e-04 - accuracy: 1.0000 - val_loss: 1.9045 - val_accuracy: 0.7767\n",
      "Epoch 290/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.8232e-04 - accuracy: 1.0000 - val_loss: 1.9074 - val_accuracy: 0.7733\n",
      "Epoch 291/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 8.6578e-04 - accuracy: 0.9996 - val_loss: 1.9114 - val_accuracy: 0.7767\n",
      "Epoch 292/300\n",
      "2400/2400 [==============================] - 0s 32us/step - loss: 5.5257e-04 - accuracy: 1.0000 - val_loss: 1.9140 - val_accuracy: 0.7800\n",
      "Epoch 293/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 5.2344e-04 - accuracy: 1.0000 - val_loss: 1.9190 - val_accuracy: 0.7800\n",
      "Epoch 294/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.4988e-04 - accuracy: 1.0000 - val_loss: 1.9244 - val_accuracy: 0.7817\n",
      "Epoch 295/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 6.1607e-04 - accuracy: 1.0000 - val_loss: 1.9265 - val_accuracy: 0.7833\n",
      "Epoch 296/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 4.1304e-04 - accuracy: 1.0000 - val_loss: 1.9280 - val_accuracy: 0.7783\n",
      "Epoch 297/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 3.3018e-04 - accuracy: 1.0000 - val_loss: 1.9478 - val_accuracy: 0.7800\n",
      "Epoch 298/300\n",
      "2400/2400 [==============================] - 0s 31us/step - loss: 6.1644e-04 - accuracy: 1.0000 - val_loss: 1.9394 - val_accuracy: 0.7800\n",
      "Epoch 299/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 5.7817e-04 - accuracy: 1.0000 - val_loss: 1.9474 - val_accuracy: 0.7833\n",
      "Epoch 300/300\n",
      "2400/2400 [==============================] - 0s 30us/step - loss: 2.7087e-04 - accuracy: 1.0000 - val_loss: 1.9434 - val_accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "fit=model.fit(x_train, y_train,\n",
    "              epochs=300, batch_size=50, \n",
    "              validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "constant-serve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for  obs in (\"accuracy\", \"loss\"):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fit.history[obs], \"r\",\n",
    "            label=obs+\" of validation data\")\n",
    "    plt.plot(fit.history[\"val_\"+obs], \"b--\",\n",
    "            label=obs+\" of validation data\")\n",
    "    plt.ylabel(obs)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "third-belief",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer is not a legal parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2696f21bef24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# call scikit grid search module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_gridsearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \"\"\"\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msk_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\LoCP_B\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mcheck_params\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparams_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'nb_epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                     raise ValueError(\n\u001b[1;32m---> 91\u001b[1;33m                         '{} is not a legal parameter'.format(params_name))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer is not a legal parameter"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# call Keras scikit wrapper\n",
    "model_gridsearch = KerasClassifier(build_fn=model, \n",
    "                        epochs=1, \n",
    "                        batch_size=50, \n",
    "                        verbose=1)\n",
    "\n",
    "# list of allowed optional arguments for the optimizer, see `compile_model()`\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# define parameter dictionary\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "# call scikit grid search module\n",
    "grid = GridSearchCV(estimator=model_gridsearch, param_grid=param_grid, n_jobs=1, cv=4)\n",
    "grid_result = grid.fit(x_train,y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-macro",
   "metadata": {},
   "source": [
    "### Step 6: Modify the Hyperparameters to Optimize Performance of the Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
